# 性能优化实现指南

## 概述

本文档提供了系统性能优化的具体实现方案。

---

## 优化策略

### 1. 缓存优化

#### 1.1 知识点切分结果缓存

**问题**：相同视频的切分结果被重复计算。

**解决方案**：使用LRU缓存缓存切分结果。

```python
from functools import lru_cache

class KnowledgePointSegmenter:
    @lru_cache(maxsize=100)
    def calculate_similarity(self, text1: str, text2: str) -> float:
        # 缓存相似度计算结果
        ...
```

**预期效果**：相似度计算速度提升 5-10倍。

#### 1.2 知识卡片生成缓存

**问题**：相同知识点的卡片被重复生成。

**解决方案**：在`KnowledgeCardGenerator`中已实现缓存机制。

**预期效果**：重复生成速度提升 10-100倍。

---

### 2. 批量处理优化

#### 2.1 批量难点识别

**问题**：逐个处理学生行为数据效率低。

**解决方案**：使用向量化计算批量处理。

```python
def optimized_batch_detect(self, behavior_data_list):
    # 批量计算困难度分数
    scores = [self.calculate_difficulty_score(bd) for bd in behavior_data_list]
    # 批量判断
    results = [self._create_result(bd, score) for bd, score in zip(behavior_data_list, scores)]
    return results
```

**预期效果**：批量处理速度提升 3-5倍。

#### 2.2 批量资源推送

**问题**：逐个推送资源效率低。

**解决方案**：使用批量推送接口。

```python
def batch_push(self, resources: List[Dict]) -> Dict:
    # 批量推送，减少网络开销
    ...
```

**预期效果**：推送速度提升 2-3倍。

---

### 3. 算法复杂度优化

#### 3.1 知识点切分算法优化

**当前复杂度**：O(n²) - 每个文本段都要与其他段计算相似度

**优化方案**：
- 使用滑动窗口：只计算相邻文本段的相似度
- 使用批量相似度计算：一次性计算多个相似度

```python
def detect_topic_shift_optimized(self, texts: List[Dict]) -> List[int]:
    # 只计算相邻文本段的相似度，复杂度从O(n²)降到O(n)
    topic_shifts = []
    for i in range(len(texts) - 1):
        similarity = self.calculate_similarity(texts[i]["text"], texts[i+1]["text"])
        if similarity < self.similarity_threshold:
            topic_shifts.append(i + 1)
    return topic_shifts
```

**预期效果**：切分速度提升 10-100倍（取决于文本段数量）。

#### 3.2 知识图谱构建优化

**当前复杂度**：O(n²) - 每个知识点都要与其他知识点比较

**优化方案**：
- 使用索引：为关键词建立索引
- 使用哈希表：快速查找相关知识点

```python
def detect_related_optimized(self, knowledge_points: List[KnowledgePointInfo]) -> List[KnowledgeRelation]:
    # 建立关键词索引
    keyword_index = {}
    for kp in knowledge_points:
        for keyword in kp.keywords:
            if keyword not in keyword_index:
                keyword_index[keyword] = []
            keyword_index[keyword].append(kp.id)
    
    # 使用索引快速查找相关知识点
    relations = []
    for kp in knowledge_points:
        related_kps = set()
        for keyword in kp.keywords:
            related_kps.update(keyword_index.get(keyword, []))
        # 只处理相关知识点
        ...
```

**预期效果**：关系检测速度提升 5-10倍。

---

### 4. 数据库查询优化

#### 4.1 添加索引

**建议索引**：
- `watch_events(user_id, knowledge_point_id)` - 复合索引
- `knowledge_points(video_id)` - 单列索引
- `mastery(user_id, knowledge_point_id)` - 复合索引

#### 4.2 批量查询

**问题**：循环查询数据库效率低。

**解决方案**：使用IN查询或批量查询。

```python
# 不好的做法
for user_id in user_ids:
    behavior = db.get_behavior(user_id, kp_id)

# 好的做法
behaviors = db.get_behaviors_batch(user_ids, kp_id)
```

---

### 5. 异步处理优化

#### 5.1 异步资源生成

**问题**：资源生成是耗时操作，阻塞主线程。

**解决方案**：使用异步处理。

```python
import asyncio

async def generate_resources_async(kp_info):
    # 异步生成知识卡片和练习题
    card_task = asyncio.create_task(generate_card_async(kp_info))
    exercise_task = asyncio.create_task(generate_exercises_async(kp_info))
    
    card, exercises = await asyncio.gather(card_task, exercise_task)
    return card, exercises
```

**预期效果**：资源生成时间减少 30-50%。

---

### 6. 内存优化

#### 6.1 使用生成器

**问题**：大量数据占用内存。

**解决方案**：使用生成器代替列表。

```python
def process_knowledge_points_generator(knowledge_points):
    # 使用生成器，不一次性加载所有数据
    for kp in knowledge_points:
        yield process_knowledge_point(kp)
```

#### 6.2 及时释放内存

**问题**：大对象占用内存不释放。

**解决方案**：及时删除不需要的对象。

```python
# 处理完数据后立即删除
result = process_large_data(data)
del data  # 释放内存
```

---

## 性能监控

### 1. 添加性能监控装饰器

```python
from performance_optimizer import PerformanceOptimizer

optimizer = PerformanceOptimizer()

@optimizer.profile_function
def your_function():
    # 自动记录函数调用次数和耗时
    ...
```

### 2. 定期运行性能测试

```bash
# 每周运行一次性能测试
python algorithm/performance_test.py
```

---

## 优化优先级

### 高优先级（立即实施）

1. ✅ **知识点切分结果缓存** - 影响最大，实施简单
2. ✅ **批量处理优化** - 显著提升批量操作性能
3. ✅ **算法复杂度优化** - 从根本上提升性能

### 中优先级（近期实施）

4. **数据库查询优化** - 需要数据库支持
5. **异步处理优化** - 需要重构部分代码

### 低优先级（长期优化）

6. **内存优化** - 当前内存使用正常
7. **分布式处理** - 需要系统架构支持

---

## 预期性能提升

| 优化项 | 当前性能 | 优化后性能 | 提升倍数 |
|--------|---------|-----------|---------|
| 知识点切分 | 1.0秒 | 0.1秒 | 10x |
| 批量难点识别 | 10秒/100条 | 2秒/100条 | 5x |
| 知识图谱构建 | 2.0秒 | 0.3秒 | 6.7x |
| 资源生成 | 0.5秒 | 0.3秒 | 1.7x |

---

## 实施步骤

1. **第一步**：实施缓存优化（1-2天）
   - 添加相似度计算缓存
   - 验证缓存效果

2. **第二步**：优化批量处理（2-3天）
   - 优化批量难点识别
   - 优化批量资源推送

3. **第三步**：优化算法复杂度（3-5天）
   - 优化知识点切分算法
   - 优化知识图谱构建算法

4. **第四步**：数据库优化（需要后端配合）
   - 添加必要索引
   - 优化查询语句

5. **第五步**：异步处理（可选）
   - 重构资源生成为异步
   - 测试异步性能

---

## 注意事项

1. **缓存失效**：确保缓存数据及时更新
2. **内存使用**：监控缓存占用的内存
3. **测试验证**：每次优化后都要运行测试验证
4. **性能监控**：持续监控系统性能

---

**最后更新**：2025-01-25
