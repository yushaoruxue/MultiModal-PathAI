### 需求规格说明书 (第一稿)

## 一、 项目背景与核心愿景

### 1.1 项目背景

本项目在蒋国伟团队前期“教学视频解析”成果基础上，进行深度的功能进阶与目标重构。针对职业教育领域，解决“学生被动看视频、知识吸收效率低、学习路径一刀切”的痛点。

### 1.2 核心愿景

- **懂学生的AI：** 实现类似“教育版淘宝”的千人千面推荐。
- **角色转变：** 让学生从“被动接收者”转变为“项目设计者/参与者”。
- **动态干预：** AI不再仅仅是播放器，而是能实时捕捉学习障碍并提供“补偿教育”的智能导师。

------

## 二、 核心功能模块需求（重点）

### 模块一：多模态语义解析与知识建模

- 多源特征提取：
  - **视觉（CV）：** 识别教学视频中的PPT文字、黑板板书、实验演示的关键动作。
  - **音频（ASR）：** 将老师讲解录音转化为文本，并识别语音中的重音（强调点）。
  - **文本：** 解析字幕及视频元数据。
- **知识图谱映射：** 将上述多模态信息转化为结构化的知识点，自动标注视频的时间戳。

### 模块二：学习者行为洞察与路径规划

- **行为数据采集：** 实时记录学习者的播放、暂停、反复观看、快进、中途退出等行为。
- 薄弱点画像：
  - 若某段视频被多人反复观看，自动标记为“公共难点”。
  - 若特定学生多次回放某片段，标记为“个体弱项”。
- **动态路径生成：** 根据画像，实时调整学习顺序。例如：跳过已掌握的基础环节，直接进入实操环节。

### 模块三：反馈补偿与干预机制

- 触发式推送：

   

  当系统检测到学习者卡顿时，主动推送：

  - **精炼短视频：** 针对该知识点的30秒原理解析。
  - **即时习题：** 弹出交互式小测验，验证理解情况。
  - **补充资源：** 相关的知识图谱节点或同类经典案例。

- **反馈闭环：** 监测补偿资源被消耗后的学习行为改善情况。

------

## 三、 业务流程说明

1. **解析阶段：** 老师上传职教视频 -> AI进行多模态分析 -> 生成知识标签索引。
2. **交互阶段：** 学生开始学习 -> AI记录点击流数据 -> 识别当前掌握状态。
3. **决策阶段：** 触发算法引擎 -> 判定是否需要干预 -> 实时调整下一阶段学习内容。
4. **补偿阶段：** 推送针对性资源 -> 学生完成补偿任务 -> 记录效果并更新学习路径。

------

## 四、 关键业务场景描述

- **场景A（职教实操）：** 学生在看一段数控机床操作视频时，在“参数设置”环节停顿很久。AI自动弹窗询问：“是否需要观看参数设置的3D拆解动画？”，学生点击观看后，AI再引导其完成一个模拟练习。
- **场景B（考前复习）：** 系统根据学生全学期的观看行为轨迹，自动生成一份“个人错难点集锦”短视频列表。

------

## 五、 技术路线与约束 (仅作参考，不作为当前重点)

- **前端：** 响应式学习平台，支持行为监测。
- **后端：** 业务逻辑处理与学习数据持久化。
- **AI引擎：** 包含多模态大模型接口（处理图文音）、推荐算法逻辑。
- **约束：** 必须优先保证对“职教知识视频”的适配，而非通用的娱乐视频。

------

## 六、 团队成员分工规划

- **组长 (周东吴)：** 项目统筹、需求定义、与老师/顾问对接。
- **需求与业务组 (成员1, 2)：** 细化职教场景下的具体痛点，撰写详细用户故事。
- **技术调研组 (成员3, 4)：** 调研多模态解析及路径生成算法的可行性。
- **技术顾问 (蒋国伟)：** 旧项目经验迁移、技术避坑指导。

------

## 七、 待解决问题 (Q&A)

1. 如何定义“学生真的不懂”？（区分走神与思考）
2. 补偿资源库的来源如何自动化生成？
3. 职业教育中的“动手实验”如何通过视频解析实现？